---
title: "Vegetation quadrat statistical analysis"
output:
  html_notebook: default
---

# Statistical analysis - vegetation quadrat

This [R Markdown](http://rmarkdown.rstudio.com) Notebook provides guidance on statistical analysis of vegetation quadrat data for the purposes of hypothesis testing, assessment of statistical power of available project data, introduction of covariates, etc. The notebook assumes you have run the relevant sections of Vegetation quadrat.R to load and preprocess data for your project of interest. Methods provided are examples which can be adapted to suit your purposes.

Pre-rendered outputs in the notebook show data for Scottsdale Reserve obtained between 2006 and 2020. Editing the notebook and pressing the 'Run Current Chunk' button on each code segment will allow you to apply these steps to your own dataset.

## Libraries

The first thing to do is to load required libraries:

```{r}
library(tidyverse)
```

## Simple linear model

We could construct a linear regression model to consider the change over time of a response variable such as the density of a particular species, or the species diversity of quadrats within a particular vegetation community.

Linear regression will produce results from a wide range of datasets, but the outputs will only be valid if the dataset contains reliable data and meets certain assumptions. For linear regression, these assumptions are linearity (that there is a linear relationship between the predictor and response variables), independence (that there is no correlation between consecutive residuals in time series data), normality (that the residuals of the model are evenly distributed), and equal variance AKA homoscedasticity (that the residuals have constant variance at all levels of the predictor variable). Our approach will be to construct a linear regression model, then to run some diagnostics on the model outputs to consider whether they are valid.

As an example, let's see if we can build a linear regression model of change in species diversity (using the Simpson index) over time for a given value of `site_target_name`.

Let's check the value of site_target_name for the first record in the veg_qdt_species tibble:

```{r}
veg_qdt_species[1,]$site_target_name
```

For convenience, we'll create a new tibble containing data from veg_qdt_site which match this value of site_target_name, and take a quick look using `glimpse()` to make sure it contains data.

```{r}
# Build dataset for model
lm_data <- veg_qdt_species %>%
  filter(site_target_name == veg_qdt_species[1,]$site_target_name)

lm_data %>% glimpse()
```

### First impressions

We can use the methods built into `ggplot()` to visualise a linear regression model for this dataset:

```{r}
# Initial visualisation
lm_data %>%
  ggplot(aes(x = survey_date, y = species_diversity_simpson)) +
  geom_point() +
  geom_smooth(method = lm) +
  theme_classic() +
  labs(x = "Survey date", y = "Species diversity (Simpson index)")
```

Is this model valid? In order to test this, let's run some diagnostics. The first step is to build the model ourselves using `lm()`.

```{r}
# Generate linear model
lm_output <- lm(species_diversity_simpson ~ survey_date, data = lm_data)
```

Let's check some summary statistics of the model we've just built:

```{r}
summary(lm_output)
```

There's a lot of information here, but we're particularly interested in the t-value and p-value (`Pr(>|t|)`) for the predictor variable survey_date, which show us the ability of this variable to predict values of our response variable.

These values give us an impression of the model's ability to describe the observations in our dataset. In particular, if we don't see a relatively high t-value and a relatively low p-value, our results aren't statistically significant and we may need to consider a different method for modelling this dataset. Symbols such as asterisks next to p-values indicate that the model describes the dataset relatively well (according to a threshold, the *alpha level*), and that we have some justification for rejecting a null hypothesis that survey_date is not a good predictor of our response variable.

These summary statistics can give us an idea of how well the model fits the data, but do not allow us to test the assumptions required for these outputs to be valid. Testing for validity is best achieved with reference to diagnostics.

### Standard diagnostics

Plots built into the linear regression model outputs provide us with some simple methods by which to test the validity of the model outputs. These generally consider residuals (the error between the model-predicted value and observed actual value).

#### Linearity and equality of variance

##### Residuals vs. fitted plot:

```{r}
plot(lm_output, 1)
```

This diagnostic plot allows us to consider the linearity of the relationship between the predictor and response variables, and the equality of variance in our dataset. A good result here would have a mean of zero (dotted line), and an even spread of residual values on both sides of the mean, with no visible pattern.

##### Scale-location plot:

```{r}
plot(lm_output, 3)
```

Like the residuals vs. fitted plot, the scale-location plot allows us to consider the linearity and equality of variance in our dataset. A good result here would have a near-horizontal line across the fitted value range, with no visible pattern.

#### Normality of errors

##### Histogram of residuals

```{r}
hist(resid(lm_output))
```

```{r}

### Standard linear model diagnostics

# Display all diagnostic plots
par(mfrow = c(2,2))
plot(lm_output)
par(mfrow=c(1,1))

## Assess linearity and equality of variance
# Residuals vs fitted
# - mean should be ~0, evenly spread, lack of obvious pattern
plot(lm_output, 1)
# Scale-location plot
# - line should be approximately horizontal
# - spread around red line shouldn't vary with fitted values
plot(lm_output, 3)

## Assess normality of errors
# Histogram of residuals
# - should display a normal distribution
hist(resid(lm_output))
# Normal quantile-quantile plot (aka Normal Q-Q)
# - plotted values should follow the dotted line
plot(lm_output, 2)
# Shapiro-Wilk normality test
# - p-value should be relatively high in order to permit us to reject the null hypothesis of a lack of normality
# - e.g. a significance level of .05
shapiro.test(resid(lm_output))

# Test failed? It may help to re-run with a transformed response variable, e.g. log-transform, and repeat these diagnostics
# lm_output <- lm(log(species_diversity_simpson) ~ survey_date, data = lm_data)
# If the test still fails, try other transforms or change approach


## Assess outliers and points with high leverage
# Residuals vs leverage
# - Spread of residuals shouldn't change as a function of leverage
# - Values with high Cook's distance (e.g. outside the dotted red line) are highly influential on the model - may represent errors
plot(lm_output,5)


# Further interrogation of outliers/influential points:
# Record labels with high Cook's distance from residuals vs. leverage plot
outlier_labels <- c(4, 9)

# Find these data points in vgt_qdt
lm_data[outlier_labels,]

# Find species observations which produced these data points
veg_qdt[outlier_labels,] %>%
  select(site_target_name, site_id, survey_year, survey_date) %>%
  left_join(veg_qdt_species) %>%
  print(n=nrow(.))

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

Test edit.

```{r}
print("Test code chunk.")
```
